{
    "base": "configs/offline_antmaze/pref_iql.yaml",
    "paired_keys": [
        ["eval_env", "dataset_kwargs.replay_kwargs.name", "dataset_kwargs.feedback_kwargs.path"]
    ],
    "eval_env": ["antmaze-medium-play-v2", "antmaze-medium-diverse-v2", "antmaze-large-play-v2", "antmaze-large-diverse-v2"],
    "dataset_kwargs.replay_kwargs.name": ["antmaze-medium-play-v2", "antmaze-medium-diverse-v2", "antmaze-large-play-v2", "antmaze-large-diverse-v2"],
    "dataset_kwargs.feedback_kwargs.path": [
        "../datasets/ihlearn/preference_transformer/antmaze-medium-play-v2/num1000_human_train.npz",
        "../datasets/ihlearn/preference_transformer/antmaze-medium-diverse-v2/num1000_human_train.npz",
        "../datasets/ihlearn/preference_transformer/antmaze-large-play-v2/num1000_human_train.npz",
        "../datasets/ihlearn/preference_transformer/antmaze-large-diverse-v2/num1000_human_train.npz"
    ],
    "alg_kwargs.reward_steps": [20000, 40000, 60000],
    "dataset_kwargs.feedback_kwargs.subsample_size": [64],
    "dataset_kwargs.feedback_kwargs.batch_size": [8],
    "network_kwargs.reward_kwargs.act": [["import", "torch.nn", "ReLU"]],
    "network_kwargs.reward_kwargs.output_act": [null],
    "seed": [1, 2]
}
